services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    healthcheck:
      test: [ "CMD", "nc", "-vz", "localhost", "2181" ]
      interval: 10s
      timeout: 3s
      retries: 3
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-log:/var/lib/zookeeper/log
      - zookeeper-secrets:/etc/zookeeper/secrets

  kafka_server:
    image: confluentinc/cp-kafka:latest
    restart: always
    healthcheck:
      test: [ "CMD", "nc", "-vz", "localhost", "9092" ]
      interval: 10s
      timeout: 3s
      retries: 3
    ports:
      - "9092:9092"
    expose:
      - "29092"
    entrypoint: /tmp/entrypoint.sh
    volumes:
      - ./entrypoint.sh:/tmp/entrypoint.sh
      - ./kafka-config.properties:/etc/kafka/kafka.properties
      - kafka-data:/var/lib/kafka/data
      - kafka-data-secrets:/etc/kafka/secrets
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: OUTSIDE://:29092,INTERNAL://:9092
      KAFKA_ADVERTISED_LISTENERS: OUTSIDE://kafka_server:29092,INTERNAL://kafka_server:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'

    depends_on:
      zookeeper:
        condition: service_healthy

  kafka_server_replica:
    image: confluentinc/cp-kafka:latest
    restart: always
    healthcheck:
      test: [ "CMD", "nc", "-vz", "localhost", "9093" ]
      interval: 10s
      timeout: 3s
      retries: 3
    ports:
      - "9093:9093"
    expose:
      - "29093"
    entrypoint: /tmp/entrypoint.sh
    volumes:
      - ./entrypoint.sh:/tmp/entrypoint.sh
      - kafka-data-replica:/var/lib/kafka/data
      - kafka-data-secrets-replica:/etc/kafka/secrets
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: OUTSIDE://:29093,INTERNAL://:9093
      KAFKA_ADVERTISED_LISTENERS: OUTSIDE://kafka_server_replica:29093,INTERNAL://kafka_server_replica:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'

    depends_on:
      zookeeper:
        condition: service_healthy


  init-kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      kafka_server:
        condition: service_healthy
      kafka_server_replica:
        condition: service_healthy
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka_server:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka_server:29092 --create --if-not-exists --topic entities-1 --replication-factor 2 --partitions 3
      kafka-topics --bootstrap-server kafka_server:29092 --create --if-not-exists --topic entities-2 --replication-factor 2 --partitions 3

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka_server:29092 --list
      "


  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8080:8080
    environment:
      DYNAMIC_CONFIG_ENABLED: true
      KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS: kafka_server:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER_CONNECT: zookeeper:2181
    depends_on:
      init-kafka:
        condition: service_completed_successfully

  consumer:
    scale: 3
    build:
      context: .
      dockerfile: ./consumer/Dockerfile.consumer
#    command: tail -F 1
    command: poetry run python start.py
    volumes:
      - ./consumer:/app
    depends_on:
      init-kafka:
        condition: service_completed_successfully
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka_server:9092

  producer:
    build:
      context: .
      dockerfile: ./producer/Dockerfile.producer
    command: poetry run python start.py
    depends_on:
      init-kafka:
        condition: service_completed_successfully
    volumes:
      - ./producer:/app
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka_server:9092

volumes:
  kafka-data: {}
  kafka-data-replica: {}
  kafka-data-secrets: {}
  kafka-data-secrets-replica: {}
  zookeeper-data: {}
  zookeeper-log: {}
  zookeeper-secrets: {}